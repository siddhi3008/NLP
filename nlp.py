# -*- coding: utf-8 -*-
"""NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Dfg3IFUAsz8XOY11llHcvW8-XZDYprG-
"""

import os
import nltk
import nltk.corpus

nltk.download('all')

print(os.listdir(nltk.data.find("corpora")))

from nltk.corpus import brown
brown.words()

nltk.download('gutenberg')

nltk.corpus.gutenberg.fileids()

hamlet=nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')
hamlet

for word in hamlet[:500]:
  print(word, sep=' ', end=' ')

AI="""Life is beautiful but not always easy, it has problems, too, and the challenge lies in facing them with courage, letting the beauty of life act like a balm, which makes the pain bearable, during trying times, by providing hope.Happiness, sorrow, victory, defeat, day-night are the two sides of the me coin. Similarly life is full of moments of joy, pleasure, success and comfort punctuated by misery, defeat, failures and problems. There is no human being on Earth, strong, powerful, wise or rich, who has not experienced, struggle, suffering or failure."""

type(AI)

from nltk.tokenize import word_tokenize

nltk.download('punkt')

AI_tokens=word_tokenize(AI)
AI_tokens

len(AI_tokens)

from nltk.probability import FreqDist
fdist= FreqDist()

for word in AI_tokens:
  fdist[word.lower()]+=1
fdist

fdist['beautiful']

fdist['and']

len(fdist)

fdist_top10 = fdist.most_common(10)
fdist_top10

from nltk.tokenize import blankline_tokenize
AI_blank=blankline_tokenize(AI)
len(AI_blank)

AI_blank[0]

from nltk.util import bigrams, trigrams, ngrams

import string

!pip3 install nltk
import nltk

nltk.download('punkt')

string = "Sing like no one’s listening, love like you’ve never been hurt, dance like nobody’s watching, and live like it’s heaven on earth."
quotes_tokens = nltk.word_tokenize(string)
quotes_tokens

quotes_tokens = list(nltk.bigrams(quotes_tokens))
quotes_tokens

quotes_tokens = list(nltk.trigrams(quotes_tokens))
quotes_tokens

quotes_ngrams = list(nltk.ngrams(quotes_tokens, 5))
quotes_ngrams

from nltk.stem import PorterStemmer
pst=PorterStemmer

nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

from nltk.stem import PorterStemmer
pst=PorterStemmer()

pst.stem("having")

words_to_stem=["give","giving","given","gave"]
for words in words_to_stem:
  print(words+ ":" +pst.stem(words))

from nltk.stem import LancasterStemmer
lst=LancasterStemmer()
for words in words_to_stem:
 print(words+ ":" +lst.stem(words))

from nltk.stem import SnowballStemmer
sbst=SnowballStemmer ('english')

for words in words_to_stem:
  print(words+ ":" +sbst.stem(words))

from nltk.stem import wordnet
from nltk.stem import WordNetLemmatizer
word_lem=WordNetLemmatizer()

nltk.download('wordnet')

from nltk.corpus import wordnet

word_lem.lemmatize('corpora')

for words in words_to_stem:
  print(words+ ":" +word_lem.lemmatize(words))

from nltk.corpus import stopwords

stopwords.words('english')

len(stopwords.words('english'))

fdist_top10

import re
punctuation=re.compile(r'[-.?!,:;()|0-9]')

post_punctuation=[]
for words in AI_tokens:
   word=punctuation.sub("",words)
   if len(word)>0:
        post_punctuation.append(word)

post_punctuation

sent = "Siddhika is good girl"
sent_tokens = word_tokenize(sent)

for token in sent_tokens:
   print(nltk.pos_tag([token]))

sent2 = "computer science engineering"
sent2_tokens = word_tokenize(sent2)
for token in sent2_tokens:
    print(nltk.pos_tag([token]))

from nltk import ne_chunk

NE_sent = "yukta stays in Nagpur"

NE_tokens = word_tokenize(NE_sent)
NE_tag = nltk.pos_tag(NE_tokens)

nltk.download('maxent_ne_chunker')
nltk.download('words')

NE_NER = ne_chunk(NE_tag)
print(NE_NER)

new = "alfiya is clever girl"
new_tokens = nltk.pos_tag(word_tokenize(new))
new_tokens

grammer_np = r"NP: {<DT>?<JJ>*<NN>}"

chunk_parser = nltk.RegexpParser(grammer_np)